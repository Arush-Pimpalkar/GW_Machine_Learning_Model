{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 14:42:34.851319: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-22 14:42:34.961212: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-22 14:42:35.373121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 14:42:36.465685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = tf.keras.preprocessing.image.load_img(\n",
    "            os.path.join(folder, filename), color_mode=\"grayscale\"\n",
    "        )\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Divide data into training and testing sets\n",
    "def split_data(folder, test_size=0.2):\n",
    "    filenames = os.listdir(folder)\n",
    "    np.random.shuffle(filenames)\n",
    "    train_files, test_files = train_test_split(filenames, test_size=test_size)\n",
    "    return train_files, test_files\n",
    "\n",
    "\n",
    "# Custom image generator for loading images from a list of file paths\n",
    "def custom_image_generator(file_paths, batch_size=32, target_size=(640, 480)):\n",
    "    num_samples = len(file_paths)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_files = file_paths[offset : offset + batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            for file_path in batch_files:\n",
    "                img = tf.keras.preprocessing.image.load_img(\n",
    "                    file_path, color_mode=\"grayscale\", target_size=target_size\n",
    "                )\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                batch_images.append(img_array)\n",
    "                # Assuming file name contains class information (e.g., 'noise' or 'signal')\n",
    "                label = 0 if \"noise\" in file_path else 1\n",
    "                batch_labels.append(label)\n",
    "            yield np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from folders\n",
    "noise_folder = \"/home/arush/GW_Test_1/Data_Generation/Data/Noise\"\n",
    "signal_folder = \"/home/arush/GW_Test_1/Data_Generation/Data/Signal\"\n",
    "\n",
    "noise_files_train, noise_files_test = split_data(noise_folder)\n",
    "signal_files_train, signal_files_test = split_data(signal_folder)\n",
    "\n",
    "train_files = [\n",
    "    os.path.join(noise_folder, filename) for filename in noise_files_train\n",
    "] + [os.path.join(signal_folder, filename) for filename in signal_files_train]\n",
    "\n",
    "test_files = [os.path.join(noise_folder, filename) for filename in noise_files_test] + [\n",
    "    os.path.join(signal_folder, filename) for filename in signal_files_test\n",
    "]\n",
    "\n",
    "# Create custom image generators\n",
    "train_generator = custom_image_generator(train_files)\n",
    "test_generator = custom_image_generator(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arush/anaconda3/envs/python39_1/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 6s/step - accuracy: 0.9587 - loss: 158.0500 - val_accuracy: 0.0809 - val_loss: 53312.3086\n",
      "Epoch 2/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 6s/step - accuracy: 0.9044 - loss: 3389.6836 - val_accuracy: 0.0637 - val_loss: 49090.0820\n",
      "Epoch 3/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m851s\u001b[0m 6s/step - accuracy: 0.8254 - loss: 3784.4727 - val_accuracy: 0.0637 - val_loss: 3691.4070\n",
      "Epoch 4/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 6s/step - accuracy: 0.8970 - loss: 308.2911 - val_accuracy: 0.9288 - val_loss: 0.6875\n",
      "Epoch 5/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 6s/step - accuracy: 0.6663 - loss: 1.2303 - val_accuracy: 0.9064 - val_loss: 0.6265\n",
      "Epoch 6/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 6s/step - accuracy: 0.8538 - loss: 0.6247 - val_accuracy: 0.9064 - val_loss: 0.5823\n",
      "Epoch 7/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 6s/step - accuracy: 0.8302 - loss: 0.5965 - val_accuracy: 0.9064 - val_loss: 0.5477\n",
      "Epoch 8/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 6s/step - accuracy: 0.8078 - loss: 0.5810 - val_accuracy: 0.9064 - val_loss: 0.5194\n",
      "Epoch 9/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 6s/step - accuracy: 0.7865 - loss: 0.5745 - val_accuracy: 0.9064 - val_loss: 0.4958\n",
      "Epoch 10/10\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m874s\u001b[0m 6s/step - accuracy: 0.7662 - loss: 0.5750 - val_accuracy: 0.9064 - val_loss: 0.4759\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8312 - loss: 0.5336\n",
      "Test Accuracy: 0.9063670635223389\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Define CNN model\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(640, 480, 1)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model using generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_files) // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_files) // batch_size,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test_generator, steps=len(test_files) // batch_size\n",
    ")\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
